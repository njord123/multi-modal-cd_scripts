{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net segmentering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setter opp initiele parametere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importerer generelle moduler\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setter overordnede variabler\n",
    "\n",
    "sensor = \"s2\"\n",
    "classes = ['background', 'built-up', 'roads']\n",
    "n_classes = len(classes)\n",
    "batch_size = 16\n",
    "learing_rate = 1e-3\n",
    "chip_size = 512\n",
    "trainingset = '512_rnd'\n",
    "name = '3cls_rnd'\n",
    "\n",
    "# sette navn på forsøk\n",
    "experiment_name = f\"{sensor}_{chip_size}_{name}_0\"\n",
    "load_experiment = None\n",
    "epochs_start = 0\n",
    "epochs_stop = 2\n",
    "\n",
    "train_path = os.path.join(f\"/data/user/imagery/{trainingset}/train\", sensor)\n",
    "test_path = os.path.join(f\"/data/user/imagery/{trainingset}/test\", sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regner ut statistikk over alle treningsbildene\n",
    "\n",
    "n_channels, mean, std = utils.img_stats(f\"/data/user/imagery/{trainingset}/*/{sensor}/img/\")\n",
    "mean = torch.tensor(mean)\n",
    "std = torch.tensor(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regner ut og setter vekter for klassene\n",
    "\n",
    "import utils\n",
    "class_weights = torch.FloatTensor(utils.weights(os.path.join(train_path, \"mask\")))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor(utils.weights(os.path.join(test_path, \"mask\")))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor([[0.1],      # background\n",
    "                                   [0.9],      # built-up\n",
    "                                   [0.9]])     # roads\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "train = dataloader.make_trainloaders(train_path, mean=mean, std=std)\n",
    "test = dataloader.make_trainloaders(test_path, mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viser bilde og maske av en tile\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tile = train[200]\n",
    "img_arr = tile[\"image\"]\n",
    "if sensor == \"s1\":\n",
    "    r = utils.pct_clip(img_arr[[1],...])\n",
    "    g = utils.pct_clip(img_arr[[0],...])\n",
    "    b = utils.pct_clip(img_arr[[1],...]) / utils.pct_clip(img_arr[[0],...])\n",
    "    rgb = np.moveaxis(np.array([r,g,b]).squeeze(), 0, -1)\n",
    "elif sensor == \"s2\":\n",
    "    r = img_arr[[3],...]\n",
    "    g = img_arr[[2],...]\n",
    "    b = img_arr[[1],...]\n",
    "    rgb = np.moveaxis(np.array([r,g,b]).squeeze(), 0, -1)\n",
    "elif sensor == \"s1s2\":\n",
    "    r = img_arr[[3],...]\n",
    "    g = img_arr[[2],...]\n",
    "    b = utils.pct_clip(img_arr[[-1],...])\n",
    "    rgb = np.moveaxis(np.array([r,g,b]).squeeze(), 0, -1)\n",
    "print(rgb.shape)\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "\n",
    "mask = tile[\"mask\"]\n",
    "print(mask.shape)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lage dataloaders\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=6, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bygger U-net og inspserer\n",
    "\n",
    "Bygging skjer i unet.py\n",
    "\n",
    "Der er også hjelpefunksjoner for å se på prediksjoner og teste ytelsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treningsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setter variabler, taps og optimalisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kjør dette vinduet før trening for å nullstille nettet\n",
    "import unet\n",
    "from torchinfo import summary\n",
    "\n",
    "net = unet.UNet(\n",
    "    encChannels=[n_channels,64,128,256,512],\n",
    "    decChannels=[512,256,128,64],\n",
    "    nbClasses=n_classes,\n",
    "    outSize=(chip_size,chip_size))\n",
    "\n",
    "display(summary(net,(batch_size,n_channels,chip_size,chip_size)))\n",
    "\n",
    "net.train()\n",
    "if torch.cuda.is_available():\n",
    "    net.to(\"cuda\")\n",
    "\n",
    "# for å laste inn trente vekter, kjør\n",
    "if load_experiment != None:\n",
    "    print(f\"loading model: {load_experiment}\")\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.to(\"cuda\")\n",
    "        net.load_state_dict(torch.load(f\"../models/{load_experiment}/models/unet_best.pt\",map_location=\"cuda\"))\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(f\"../models/{load_experiment}/models/unet_best.pt\",map_location=\"cpu\"))\n",
    "\n",
    "# definer tapsfunksjon og optimeringsalgoritme\n",
    "import torch.optim as optim\n",
    "import torch.nn  as nn\n",
    "\n",
    "lossfunc = nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "optimizer = optim.AdamW(net.parameters(), lr=learing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# åpne tensorboard med kommandoen \"tensorboard --logdir=models\" fra anaconda prompt fra prosjektmappen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"../models/{experiment_name}/models\",exist_ok=True)\n",
    "os.makedirs(f\"../models/{experiment_name}/inference\",exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"../models/{experiment_name}\")\n",
    "\n",
    "accuracy_log = []\n",
    "current_best = 0.1\n",
    "#num_batches = 100\n",
    "num_batches = len(trainloader)\n",
    "test_interval = 200\n",
    "num_test_batches = 50\n",
    "\n",
    "for e in range(epochs_start,epochs_stop):\n",
    "    # lage variabler for totalt tap\n",
    "    \n",
    "    running_loss = 0\n",
    "    for i,batch in enumerate(trainloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"mask\"]\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "\n",
    "        # log net graph to writer\n",
    "        if i == 0 and e == 0:\n",
    "            writer.add_graph(net,images)\n",
    "\n",
    "        out = net(images)\n",
    "        loss = lossfunc(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % test_interval == test_interval-1 or i == 0:\n",
    "            if i == 0:\n",
    "                avg_loss = running_loss\n",
    "            else:\n",
    "                avg_loss = running_loss/(test_interval)\n",
    "\n",
    "            print(f\"ep: {e+1}: batch: {(i+1)} Avg batch loss {avg_loss}\")\n",
    "            writer.add_scalar(\"Loss/loss\",avg_loss,e*num_batches + i)\n",
    "            running_loss = 0\n",
    "        \n",
    "            recall, precision, map = unet.test_accuracy(net,testloader,batch_lim=num_test_batches)\n",
    "            if np.isnan(precision):\n",
    "                    precision = 0\n",
    "            if np.isnan(recall):\n",
    "                recall = 0\n",
    "            if np.isnan(map):\n",
    "                ap = 0\n",
    "\n",
    "            accuracy = (recall+precision)/2\n",
    "            if precision+recall < 1e-8:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "            print(f\"Precision {precision}   Recall {recall}     mAP {map}    F1 {f1}\")\n",
    "            writer.add_scalar(\"Accuracy/Val/Recall\",recall,e*num_batches + i)\n",
    "            writer.add_scalar(\"Accuracy/Val/Precision\",precision,e*num_batches+i)\n",
    "            writer.add_scalar(\"Accuracy/Val/F1\",f1,e*num_batches+i)\n",
    "            writer.add_scalar(\"Accuracy/Val/mAP\",map,e*num_batches+i)\n",
    "            if map > current_best:\n",
    "                torch.save(net.state_dict(),f\"../models/{experiment_name}/models/unet_best.pt\")\n",
    "                current_best = map\n",
    "                print(\"new model saved\")\n",
    "            torch.save(net.state_dict(),f\"../models/{experiment_name}/models/unet_latest.pt\")\n",
    "\n",
    "            # lagre eksempel på inference etter hver epoke\n",
    "            step = str(e*num_batches+i).zfill(6)\n",
    "            it = iter(testloader)\n",
    "            fig = unet.view_prediction(sensor, net, next(it), save_as=f\"../models/{experiment_name}/inference/{step}_1.png\", show=False)\n",
    "            writer.add_figure(\"Sample Prediction/1\", fig, e*num_batches + i, close=True)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspisere resultater fra den trente modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definer et nett\n",
    "\n",
    "import unet\n",
    "\n",
    "# experiment_name = \"s2_test_unet_03\"\n",
    "\n",
    "net = unet.UNet(\n",
    "    encChannels=[n_channels,64,128,256,512],\n",
    "    decChannels=[512,256,128,64],\n",
    "    nbClasses=n_classes,\n",
    "    outSize=(chip_size,chip_size))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.load_state_dict(torch.load(f\"../models/{experiment_name}/models/unet_best.pt\",map_location=\"cuda\"))\n",
    "    net = net.to(\"cuda\")\n",
    "else:\n",
    "    net.load_state_dict(torch.load(f\"../models/{experiment_name}/models/unet_best.pt\",map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(loop)\n",
    "unet.view_prediction(sensor, net,batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
